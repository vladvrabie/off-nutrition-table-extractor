{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "## Modules\n",
    "- [crop](#crop)\n",
    "- [detect_table_class](#detect_table_class)\n",
    "- [detection](#detection)\n",
    "- [fuzzydict]()\n",
    "- [nutrient_list]()\n",
    "- [process](#process)\n",
    "- [regex]()\n",
    "- [resize]()\n",
    "- [spacial_map]()\n",
    "- [symspell]()\n",
    "- [text_detection_class]()\n",
    "- [text_detection](#text_detection)\n",
    "\n",
    "IMPORTANT Notes:\n",
    "- apparently it is a convention to work in BGR color space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detection' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detection.py\n",
    "\n",
    "Uses cv2\n",
    "\n",
    "Imports: [detect_table_class](#detect_table_class), [crop](#crop), [text_detection](#text_detection), [process](#process), regex, nutrient_list, spacial_map\n",
    "\n",
    "## Functions:\n",
    "\n",
    "```python\n",
    "load_model():\n",
    "```\n",
    "Creates object of class NutritionTableDetector\n",
    "\n",
    "\n",
    "```python\n",
    "detect(img_path, debug):\n",
    "```\n",
    "Debug param is for printing time taken along the function at different steps; writes cropped bounding rect to disk;\n",
    "\n",
    "Reads the image. Gets results from NutritionTableDetector. Crops from the image the bounding rect with highest confidence.\n",
    "\n",
    "Preprocesses the cropped image.\n",
    "\n",
    "It passes it to networks which detect bounding boxes for text regions.\n",
    "\n",
    "The bounding boxes are then used in ocr. Constructs a dict with bounding box, text detected, centre and text type (words, numbers or both).\n",
    "Then it tries to concatenate boxes on the same line to have the words and their corresponding numbers in the same rectangle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detect_table_class' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detect_table_class.py\n",
    "\n",
    "Uses tensorflow 1.x and numpy.\n",
    "\n",
    "```python\n",
    "class NutritionTableDetector\n",
    "```\n",
    "- hardcoded path to inference graph\n",
    "\n",
    "## Members:\n",
    "- `self.detection_graph`\n",
    "- `self.image_tensor` - input tensor\n",
    "- `self.d_boxes` - detection_boxes; output tensor\n",
    "- `self.d_scores` - detection_scores; output tensor\n",
    "- `self.d_classes` - detection_classes; output tensor\n",
    "- `self.num_d` - num_detections; output tensor\n",
    "- `self.sess` - tensorflow session\n",
    "\n",
    "## Methods:\n",
    "\n",
    "```python\n",
    "get_classification(self, img):\n",
    "```\n",
    "Given an image (with shape (height, width, 3)), it returns the tuple of boxes, scores, classes, number_detections \n",
    "\n",
    "Are results ordered by confidence ??\n",
    "\n",
    "boxes is an array of shape (-1, -1, 4) ? The 4-tuples are (ymin, xmin, ymax, xmax) in \\[0, 1\\] float variables (this makes them independent of the original shape of the image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crop' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop.py\n",
    "\n",
    "Uses cv2\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "crop(image_obj, coords, saved_location, extend_ratio=0, SAVE=False)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param image_path: The image object to be cropped\n",
    "    @param coords: A tuple of x/y coordinates (x1, y1, x2, y2)\n",
    "    @param saved_location: Path to save the cropped image\n",
    "    @param extend_ratio: The value by which the bounding boxes to be extended to accomodate the text that has been cut\n",
    "    @param SAVE: whether to save the cropped image or not\n",
    "    \"\"\"\n",
    "    \n",
    "Computes extended coordinates (where is this useful?) and crops the image. If SAVE, then writes it to the saved_location. Returns cropped image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses cv2, PIL, pytesseract, numpy\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "preprocess_for_ocr(img, enhance=1)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param img: image to which the pre-processing steps being applied\n",
    "    \"\"\"\n",
    "If enhance > 1, then it enhances the contrast (with PIL) by factor enhance.\n",
    "Commented gaussing blurr.\n",
    "Returns the image.\n",
    "\n",
    "```python\n",
    "ocr(img, oem=1, psm=3)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param img: The image to be OCR'd\n",
    "    @param oem: for specifying the type of Tesseract engine( default=1 for LSTM OCR Engine)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_detection' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_detection.py\n",
    "\n",
    "Uses cv2, numpy\n",
    "\n",
    "Imports [text_detection_class](#text_detection_class) and things from lib\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "load_text_model()\n",
    "```\n",
    "Creates object of class NutritionTextDetector.\n",
    "\n",
    "```python\n",
    "resize_im(im, scale, max_scale=None)\n",
    "```\n",
    "Resizes an image (enlarges it?) but keeps aspect ratio\n",
    "\n",
    "```python\n",
    "text_detection(img)\n",
    "```\n",
    "Resizes the image to have min 600 width or height and max 1200 width or height.\\\n",
    "Converts the image to an array suited as input to a network - shape (1, max_height, max_width, 3) which is suited for working with multiple images. This array is 'blob' - a dict. (It scales the image so that the minimum side has at least 600 pixels and the maximum side has at most 1000 - i guess it is connected to the network I/O)\\\n",
    "'blob' dict with keys 'data' and 'rois'.\\\n",
    "After all of this preprocessing, it is passed to the text detection (region proposal) network which returns 'cls_prob' and 'box_pred'.\\\n",
    "From what I can tell, box_pred contains predictions of bounding boxes where text might be (although the shape is a bit weird - don't know why it's a matrix, but explains the last axis).\\\n",
    "And cls_prob contains the confidence scores for those bounding boxes separated in foreground and background probabilities (same shape matrix, but explains last axis).\\\n",
    "These outputs are passed to a function which processes them to bounding boxes in image space.\\\n",
    "After that they are passed to an TextDetector class (in lib.text_connector) which uses graphs to connect all the boxes and detect text lines. It is set by default to detect horizontal text (TO BE TESTED). It returns text boxes in an array of shape (N, 9) where the 9 values for each box are the corners (top-left, top-right, bottom-left, bottom-right) and the score. (Implementation detail: the boxes are also filtered for relevance and shape).\n",
    "Finally, the boxes are converted back to (xmin, ymin, xmax, ymax) compact form and the score is dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_detection_class' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_detection_class.py\n",
    "\n",
    "Uses cv2, numpy and tensorflow\n",
    "\n",
    "```python\n",
    "class NutritionTextDetection:\n",
    "```\n",
    "\n",
    "This is a Region Proposal network\n",
    "\n",
    "## Members\n",
    "- `self.detection_graph`\n",
    "- `self.sess` - tensorflow session\n",
    "- `self.input_img` - 'Placeholder' tensor\n",
    "- `self.output_cls_prob` - 'Reshape_2' tensor; output shape: (1, H, W, 2xA)\n",
    "- `self.output_box_pred` - 'rpn_bbox_pred/Reshape_1' tensor; output shape: (1, H, W, 4xA)\n",
    "\n",
    "## Methods\n",
    "\n",
    "```python\n",
    "get_text_classification(self, blobs):\n",
    "```\n",
    "\n",
    "blobs is dict with 'data' key\n",
    "\n",
    "Returns (cls_prob, box_pred)\n",
    "\n",
    "Read about region proposal networks. They just give bounding boxes where text might be?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
