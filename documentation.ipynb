{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "## Modules\n",
    "- [crop](#crop)\n",
    "- [detect_table_class](#detect_table_class)\n",
    "- [detection](#detection)\n",
    "- [fuzzydict]()\n",
    "- [nutrient_list]()\n",
    "- [process](#process)\n",
    "- [regex]()\n",
    "- [resize]()\n",
    "- [spacial_map]()\n",
    "- [symspell]()\n",
    "- [text_detection_class]()\n",
    "- [text_detection](#text_detection)\n",
    "\n",
    "IMPORTANT Notes:\n",
    "- apparently it is a convention to work in BGR color space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detection' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detection.py\n",
    "\n",
    "Uses cv2\n",
    "\n",
    "Imports: [detect_table_class](#detect_table_class), [crop](#crop), [text_detection](#text_detection), [process](#process), regex, nutrient_list, spacial_map\n",
    "\n",
    "## Functions:\n",
    "\n",
    "```python\n",
    "load_model():\n",
    "```\n",
    "Creates object of class NutritionTableDetector\n",
    "\n",
    "\n",
    "```python\n",
    "detect(img_path, debug):\n",
    "```\n",
    "Debug param is for printing time taken along the function at different steps; writes cropped bounding rect to disk;\n",
    "\n",
    "Reads the image. Gets results from NutritionTableDetector. Crops from the image the bounding rect with highest confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detect_table_class' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detect_table_class.py\n",
    "\n",
    "Uses tensorflow 1.x and numpy.\n",
    "\n",
    "```python\n",
    "class NutritionTableDetector\n",
    "```\n",
    "- hardcoded path to inference graph\n",
    "\n",
    "## Members:\n",
    "- `self.detection_graph`\n",
    "- `self.image_tensor` - input tensor\n",
    "- `self.d_boxes` - detection_boxes; output tensor\n",
    "- `self.d_scores` - detection_scores; output tensor\n",
    "- `self.d_classes` - detection_classes; output tensor\n",
    "- `self.num_d` - num_detections; output tensor\n",
    "- `self.sess` - tensorflow session\n",
    "\n",
    "## Methods:\n",
    "\n",
    "```python\n",
    "get_classification(self, img):\n",
    "```\n",
    "Given an image (with shape (height, width, 3)), it returns the tuple of boxes, scores, classes, number_detections \n",
    "\n",
    "Are results ordered by confidence ??\n",
    "\n",
    "boxes is an array of shape (-1, -1, 4) ? The 4-tuples are (ymin, xmin, ymax, xmax) in \\[0, 1\\] float variables (this makes them independent of the original shape of the image)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='crop' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# crop.py\n",
    "\n",
    "Uses cv2\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "crop(image_obj, coords, saved_location, extend_ratio=0, SAVE=False)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param image_path: The image object to be cropped\n",
    "    @param coords: A tuple of x/y coordinates (x1, y1, x2, y2)\n",
    "    @param saved_location: Path to save the cropped image\n",
    "    @param extend_ratio: The value by which the bounding boxes to be extended to accomodate the text that has been cut\n",
    "    @param SAVE: whether to save the cropped image or not\n",
    "    \"\"\"\n",
    "    \n",
    "Computes extended coordinates (where is this useful?) and crops the image. If SAVE, then writes it to the saved_location. Returns cropped image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='process' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process.py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses cv2, PIL, pytesseract, numpy\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "preprocess_for_ocr(img, enhance=1)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param img: image to which the pre-processing steps being applied\n",
    "    \"\"\"\n",
    "If enhance > 1, then it enhances the contrast (with PIL) by factor enhance.\n",
    "Commented gaussing blurr.\n",
    "Returns the image.\n",
    "\n",
    "```python\n",
    "ocr(img, oem=1, psm=3)\n",
    "```\n",
    "    \"\"\"\n",
    "    @param img: The image to be OCR'd\n",
    "    @param oem: for specifying the type of Tesseract engine( default=1 for LSTM OCR Engine)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_detection' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_detection.py\n",
    "\n",
    "Uses cv2, numpy\n",
    "\n",
    "Imports [text_detection_class](#text_detection_class) and things from lib\n",
    "\n",
    "## Functions\n",
    "\n",
    "```python\n",
    "load_text_model()\n",
    "```\n",
    "Creates object of class NutritionTextDetector.\n",
    "\n",
    "```python\n",
    "resize_im(im, scale, max_scale=None)\n",
    "```\n",
    "Resizes an image (enlarges it?) but keeps aspect ratio\n",
    "\n",
    "```python\n",
    "text_detection(img)\n",
    "```\n",
    "Resizes the image to have min 600 width or height and max 1200 width or height.\\\n",
    "Converts the image to an array suited as input to a network - shape (1, max_height, max_width, 3) which is suited for working with multiple images. This array is 'blob' - a dict. (It scales the image so that the minimum side has at least 600 pixels and the maximum side has at most 1000 - i guess it is connected to the network I/O)\\\n",
    "After all of this preprocessing, it is passed to the text detection network which returns 'cls_prob' and 'box_pred'.\\\n",
    "Those are passed to ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='text_detection_class' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text_detection_class.py\n",
    "\n",
    "Uses cv2, numpy and tensorflow\n",
    "\n",
    "```python\n",
    "class NutritionTextDetection:\n",
    "```\n",
    "\n",
    "## Members\n",
    "- `self.detection_graph`\n",
    "- `self.sess` - tensorflow session\n",
    "- `self.input_img` - 'Placeholder' tensor\n",
    "- `self.output_cls_prob` - 'Reshape_2' tensor\n",
    "- `self.output_box_pred` - 'rpn_bbox_pred/Reshape_1' tensor\n",
    "\n",
    "## Methods\n",
    "\n",
    "```python\n",
    "get_text_classification(self, blobs):\n",
    "```\n",
    "\n",
    "blobs is dict with 'data' key\n",
    "\n",
    "Returns (cls_prob, box_pred)\n",
    "\n",
    "Classifies text from an image (after it has been processed, nutrition table detected and ocr'd - i think) whether it relevant nutritional data or not? Not sure. Maybe it's just ocr."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
